---
title: "Selecting Biomarkers and Making Predictions"
author: "Ellis Patrick"
date: "29 June 2018"
output:
  html_document:
    code_folding: hide
    number_sections: yes
    self_contained: yes
    toc: true
    toc_float: true
    toc_depth: 1
    theme: yeti
---

```{r, echo = FALSE}
library(knitr)
opts_knit[["set"]](root.dir = "/home/dario/Documents/tutorial/")
options(width = 91)
```

# Activity Overview

- RNA-seq Data Set: Acute Myeloid Leukaemia Treatment Resistance

- ClassifyR: Biomarker Selection Methods and Cross-validation

- Differential Means and Differential Distribution Classifiers for Classifying AML Patients

# RNA-seq Data Set: Acute Myeloid Leukaemia (AML) Treatment Resistance

- Primary therapy resistance is a major problem in acute myeloid leukemia treatment. Approximately 20â€“30% of younger adult patients with AML and as many as 50% of older adults are refractory to induction treatment.

- Research findings are <a href="http://www.haematologica.org/content/103/3/456" target="_blank">published</a> in *Haematologica* in 2018.

- The data is available from <a href="https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE106291" target="_blank">GEO Browser</a> as 250 `txt.gz` files of gene-level read counts or a Microsoft Excel file where the gene expression values were standardised to have a mean of 0 and variance of 1.

# Data Import and Exploration

Import the prepared tab-separated text files of RNA-seq read counts and clinical data.<br>
**Hint**: The `read.delim` function should be used. The matrix contains integers, so convert it to a `matrix` after import.

```{r}
readCounts <- read.delim("data/counts.txt", check.names = FALSE)
readCounts <- as.matrix(readCounts)
sampleInfo <- read.delim("data/samples.txt", check.names = FALSE)
```

`check.names = FALSE` prevents R unnecessarily changing hyphens and spaces in column names to periods.

## The Clinical Data

The cinical data provides information about several different characteristics of the patients. Verify that there is data for 250 patients.<br>
**Hint**: `sampleInfo` is a `data.frame`. Each row stores data for one patient.

```{r}
head(sampleInfo)
nrow(sampleInfo)
```

Observe the number of samples which are resistant to treatment and which are not.

```{r}
table(sampleInfo[, "Response"])
```

$164 + 71 = 235$, so there are 15 patients with missing data regarding their resistance. Identify which rows of the clinical data they are in and remove the samples.

```{r}
removeClinical <- which(is.na(sampleInfo[, "Response"]))
readCounts <- readCounts[, -removeClinical]
sampleInfo <- sampleInfo[-removeClinical, ]
```

# Properties of RNA-seq Measurements

RNA-seq count tables have a couple of properties which need to be accounted for.

1. Different samples may have a different total number of reads. A particular sample with 10 million reads will have 0 reads counted for genes that will have non-zero counts if the same sample had 100 million reads.

2. The variance of counts increases as the mean count increases when considering the trend based on all of the genes. Most classifiers require that the input data set have a constant variance across the range of means.

## Read Total / Library Size Differences

As typical for omics data and in contrast to clinical data, the genes are stored in rows and the samples in columns. Identify the number of genes and samples.<br>
**Hint**: Use either `dim` or `nrow` and `ncol` functions.

```{r}
readCounts[1:5, 1:5]
dim(readCounts)
```

For the later classifcation exercises, the number of samples will be reduced to reduce the running time. The number of reads per sample varies widely betwen patients by as much as 10-fold.

```{r}
samplesCounts <- colSums(readCounts)
countsSummary <- summary(samplesCounts)
countsSummary
```

The limit of detection would be quite different between samples.

Remove all genes with zero counts in 200 or more samples.<br>
**Hint**: Use `apply` to process each row and use `==` to test for zeros.

```{r}
removeGenes <- apply(readCounts, 1, function(geneCounts) sum(geneCounts == 0) > 200)
readCounts <- readCounts[!removeGenes, ]
```

For a visual representation, a boxplot is used to show the differences in gene counts of the first 50 samples which are simply in lexical order. The boxplots would all have been at zero if the zero rows weren't removed in the previous task, which constitute a large part of the count table.

```{r, fig.height = 6, fig.width = 12}
boxplot(readCounts[, 1:50], ylim = c(0, 1500),
        main = "Gene Counts", ylab = "Count", cex = 0.25, xaxt = 'n')
```

Identify in which columns of the matrix patients with less than the first quartile of counted reads and more than the third quartile are to remove them from the analysis.

```{r}
removeRNA <- which(samplesCounts < countsSummary["1st Qu."] |
                   samplesCounts > countsSummary["3rd Qu."])
readCounts <- readCounts[, -removeRNA]
sampleInfo <- sampleInfo[-removeRNA, ]
```

Calculate the number of remanining samples belonging to each class.

```{r}
classes <- sampleInfo[, "Response"]
table(classes)
```

The classification task is moderately imbalanced.

Scale each sample's counts to be the same as the sample in the first column.<br>
**Hint**: Calculate the ratio of each column's sum of counts to the first column's sum of counts. Then, multiply the counts in each column by that scaling factor.

```{r}
scaleFactors <- colSums(readCounts)[1] / colSums(readCounts)
scaledCounts <- t(t(readCounts) * scaleFactors)
```

Note how the disributions of counts per patient are now quite similar.

```{r, fig.height = 6, fig.width = 12}
boxplot(scaledCounts[, 1:50], ylim = c(0, 1500),
        main = "Gene Counts", ylab = "Scaled Count", cex = 0.25, xaxt = 'n')
```

## Increasing Mean and Variance

The Bioconductor package [EDASeq](https://bioconductor.org/packages/release/bioc/html/EDASeq.html) contains function for **e**xploratory **d**ata **a**nalysis of RNA-**seq**. Observe the mean-variance relationship of the scaled counts.<br>
**Hint**: EDASeq doesn't work with a matrix, but a `SeqExpressionSet` object. Read the documentation for how to create one by using the R command `?SeqExpressionSet`. A mean-variance plot can be drawn by `meanVarPlot`.

```{r, message = FALSE, warning = FALSE, fig.align = "center", fig.height = 5, fig.width = 5}
library(EDASeq)
AMLExpressionSet <- newSeqExpressionSet(scaledCounts)
meanVarPlot(AMLExpressionSet, log = TRUE, main = "Mean-Variance Plot")
```

The red line is calculated from the data whereas the black line shows the mean and variance being the same value. Notice how the experimental variance increases at a faster rate than the mean $\equiv$ variance line, a trend commonly termed _overdispersion_.

Using DESeq2's `varianceStabilizingTransformation` function, remove the relationship of variance to mean. Add the normalised values into the `AMLExpressionSet` object.<br>
**Hint**: Check the documentation of `normCounts` for how to add normalised values to a `SeqExpressionSet` object.


```{r, warning = FALSE}
library(DESeq2)
measurementsVS <- varianceStabilizingTransformation(readCounts)
normCounts(AMLExpressionSet) <- measurementsVS
```

Visualise again the relationship between mean and variance.

```{r, fig.align = "center", fig.height = 5, fig.width = 5}
meanVarPlot(AMLExpressionSet, xlim = c(3, 9), ylim = c(0, 9), main = "Mean-Variance Plot")
```

Notice that the variance is now fairly constant across the range of means.

Before doing any classification, the number of genes will be reduced to make feature selection faster. Keep the top 2000 most variable genes.<br>
**Hint**: Use `var` in conjunction with `apply` to calculate the variance of each row of the stabilised values. Use `?order` to check how to make the `order` function sort values in descending order.

```{r}
geneVariances <- apply(measurementsVS, 1, var)
mostVariable <- order(geneVariances, decreasing = TRUE)[1:2000]
measurementsVS <- measurementsVS[mostVariable, ]
measurementsVS[1:6, 1:6]
```

Class information is not used, so the filtering is fair. The most variable gene is XIST, a gene involved with X chromosome inactivation, a process by which one of the two copies of the X chromosome present in female mammals is inactivated.

# ClassifyR

- A *framework* for feature selection, cross-validated classification and its performance evaluation.

- Some popular feature selection methods and classifiers implemented in the package.

- Runs cross-validation in parallel on Windows, MacOS, Linux operating systems.

- Supports numeric-only (`matrix`) data, mixed numeric-categorical (`DataFrame`) data and multi-omics data (`MultiAssayExperiment`).

- Continually maintained and supported (first released in 2014).

## Parameter Objects

- Each stage of classification is defined by a parameter object.

- The four main types of objects are `TransformParams`, `SelectParams`, `TrainParams` and `PredictParams`.

- `TransformParams` and `SelectParams` are optional.

## Cross-validation

- The process of creating many different training and test sets is handled by `runTests`.

- The `seed` option allows the specification of a number which results in cross-validations which rely on random splits to be reproduced if the code is rerun, even if it runs on multiple cores.

- The result of running `runTests` is a `ClassifyResult` object, which many performance evaluation functions use.

- A `ClassifyResult` object stores the class predictions and possibly also class scores as well as the features selected at each cross-validation iteration.

## Parallel Processing

- By default, 2 less cores than the computer has are used.

- On Windows, use `parallelParams = SnowParam(workers = 8)` to use 8 cores and on Linux or MacOS use `parallelParams = MulticoreParam(workers = 8)` as an argument to achieve the same customisation.

## Getting Help

- Every Bioconductor package has a vignette which demonstrates the main usage on an example data set. ClassifyR's HTML vignette is available from the <a href="https://bioconductor.org/packages/release/bioc/html/ClassifyR.html" target="_blank">package's home page</a>.

- The <a href="https://support.bioconductor.org/" target="_blank">Bioconductor Support Forum</a> is the best communication channel to ask questions about Bioconductor packages, such as ClassifyR.

# DLDA - Differential Means Classifier for AML Resistance

Load ClassifyR.

```{r, message = FALSE}
library(ClassifyR)
```

- The default feature selection method of `SelectParams` is a moderated t-test based ranking and selection of the top $p$ genes that give the best resubstitution error (considering 10, 20, ..., 100 top-ranked features). See `?SelectParams` for the specification.

- The default training and prediction methods for `TrainParams` and `PredictParams` are for Diagonal Linear Discriminant Analysis (DLDA). See `?TrainParams` and `?PredictParams` for the specification.

A 20 permutations and 5 folds cross-validation using default selection and classification methods is done using `runTests`. Read its documentation to understand the options available.

```{r}
classifiedDM <- runTests(measurementsVS, classes, "AML", "Changes in Means",
                         permutations = 20, seed = 2018)
classifiedDM
```

Doing this manually would be time consuming and difficult. The same classification written using simple R statements is long and there are many opportunities for introducing errors. There is no need to run it, but appreciate the complexity of the code.

```{r, eval = FALSE}
sampleOrdering <- lapply(1:20, function(permutation) sample(ncol(measurements)))
sampleFold <- rep(1:5, length.out = ncol(measurements))
samplesFolds <- lapply(sampleOrdering, function(sample) split(sample, sampleFold))
library(limma)
library(sparsediscrim)

results <- lapply(1:20, function(permuteIndex)
{
  lapply(1:5, function(foldIndex)
  {
    # Subsetting of measurements and classes for training and test sets
    testIndices <- samplesFolds[[permuteIndex]][[foldIndex]]
    trainingValues <- measurementsVS[, -testIndices]
    trainingClasses <- classes[-testIndices]
    testingValues <- measurementsVS[, testIndices]
    testClasses <- classes[testIndices]
    
    # Ranking by moderated t-test
    linearModel <- lmFit(trainingValues, model.matrix(~ trainingClasses))
    linearModel <- eBayes(linearModel)
    topFeatures <- topTable(linearModel, coef = 2, number = Inf, sort.by = "p")
    topIndices <- match(rownames(topFeatures), rownames(measurementsVS))
    
    # Picking the best top-p features based on resubstitition error.
    resubErrors <- numeric()
    topTry <- seq(10, 100, 10)
    resubErrors <- lapply(topTry, function(topF)
    {
      trained <- dlda(t(trainingValues)[, topIndices[1:topF]], trainingClasses)
      predicted <- predict(trained, t(trainingValues)[, topIndices[1:topF]])[["class"]]
      sum(predicted != trainingClasses)
    })
    topF <- topTry[which.min(resubErrors)[1]] # Smallest in case of ties.
    
    # Training and prediction.
    useFeatures <- rownames(measurementsVS)[topIndices[1:topF]]
    trained <- dlda(t(trainingValues)[, useFeatures], trainingClasses)
    predicted <- predict(trained, t(testingValues)[, useFeatures])
    
    list(chosen = useFeatures,
         predictions = data.frame(ID = colnames(testingValues),
                                  class = predicted[["class"]]))
  })
})
```

- Access the chosen features by using the `features` accessor, which extracts all of the feature selections at each iteration of cross-validation. View the features chosen in folds 1 and 2 of permutation 1.<br>
**Hint**: The features are in a list of lists. The top-level list contains one element for each iteration and the second-level list contains one element for each fold.


```{r}
# Permutation 1, folds 1 and 2.
features(classifiedDM)[[1]][1:2]
```

- The `predictions` accessor gets all of the class predictions. View the first few predictions of the first permutation.<br>
**Hint**: The predictions are stored in a list, one for each permutation and have as many rows as there are samples. Use `head` to limit the number of predictions displayed.

```{r}
# Permutation 1
head(predictions(classifiedDM)[[1]])
```

The `distribution` function calculates the feature selection frequency of all features. Use `?distribution` to find out about it and determine the most frequently selected feature.<br>
**Hint**: Use the `sort function` on the output of the `distribution` function.

## Most Frequently Selected Feature

```{r}
frequencies <- distribution(classifiedDM, plot = FALSE)
frequencies <- sort(frequencies, decreasing = TRUE)
head(frequencies)
```

`r names(frequencies)[1]` is chosen `r frequencies[1]` out of 100 possible times.

The distribution of gene expression per class can be quickly visualised with `plotFeatureClasses`.<br>
**Hint**: The `targets` parameter of `plotFeatureClasses` specifies one or more features to be plotted.

```{r, fig.height = 4, fig.width = 7, fig.align = "center"}
plotFeatureClasses(measurementsVS, classes, targets = names(frequencies)[1],
                   whichNumericPlots = "density", xAxisLabel = "RNA-seq Abundance")
```

The gene is visibly differentially expressed between resistant and sensitive patients.

## Clinical Data Quality Check

ZFY is a gene on the Y chromosome which only males have. Plot its expression with the gender in place of the treatment resistance classes.

```{r, fig.height = 4, fig.width = 7, fig.align = "center"}
plotFeatureClasses(measurementsVS, sampleInfo[, "Gender"], targets = "ZFY",
                   whichNumericPlots = "density", xAxisLabel = "RNA-seq Abundance")
```

The abundance grouped by gender is as expected.

# Logsitic Regression - DM Classifier for AML Resistance Using Clinical Data

- Classifier built using only the routinely collected clinical information.

- *Multinomial* logistic regression is not available by default in R, but is available from mnlogit.

- `logisticRegressionTrainInterface` is a wrapper around the `mnlogit` fitting function.

- `logisticRegressionPredictInterface` is a wrapper around the `predict` function for objects of class `mnlogit`.

Specify the training and prediction parameter settings.<br>
**Hint**: Use `?logisticRegressionTrainInterface` and note that it returns a vector of classes. Therefore, specify an identity function for `getClasses` to `PredictParams`.

```{r}
trainParams <- TrainParams(logisticRegressionTrainInterface)
predictParams <- PredictParams(logisticRegressionPredictInterface,
                               getClasses = function(result) result)
```

Run 20 permutations and 5 folds cross-validation, ignoring GEO ID, Survival Time and Status.

```{r}
ignoreColumns <- match(c("ID", "Survival Time", "Status"), colnames(sampleInfo))
ignoreColumns
classifiedClinical <- runTests(DataFrame(sampleInfo[, -ignoreColumns]), "Response",
                               "AML", "Clinical",
                               params = list(trainParams, predictParams),
                               permutations = 20, seed = 2018)
classifiedClinical
```

# naive Bayes - Differential Distribution (DD) Classifier for AML Resistance

Numerous DD selection methods are available in ClassifyR. <a href="https://bioconductor.org/packages/release/bioc/vignettes/ClassifyR/inst/doc/ClassifyR.html#provided-feature-selection-and-classification-methods" target="_blank">Section 0.9 of the vignette</a> gives an overview. For this example, Kullback-Leibler divergence will be used. Navigate to the Reference Manual (PDF) of <a href="https://bioconductor.org/packages/release/bioc/html/ClassifyR.html" target="_blank">ClassifyR</a> to see the formula.

Create a selection parameter object specifying the use of Kullback-Leibler feature selection.<br>
**Hint**: `KullbackLeiblerSelection` is the name of the function to be specified. Information about the type of location and scale calculated is documented for `...`

```{r}
selectParams <- SelectParams(KullbackLeiblerSelection,
                             resubstituteParams = ResubstituteParams())
```

By default, the mean is the location and the standard deviation is the scale.

A variety of DD classifiers are available in ClassifyR. For this example, the naive Bayes method will be used. The difference of the height (scaled by the number of samples in each class) between the kernel densities of the two classes is used by each gene to vote for one class. The class with the most votes is the predicted class of the patient.

Create a training parameter object specifying the use of the naive Bayes classifier.

```{r}
trainParams <- TrainParams(naiveBayesKernel)
```

Create a prediction parameter object specifying the use the height difference between densities and unweighted voting. `naiveBayesKernel` trains a classifier and returns a factor vector of class predictions, so there is no other function used for predictions.<br>
**Hint**: Use `?naiveBayesKernel` to see the names of the parameters controlling the voting process. Specify an identity function for `getClasses`.

```{r}
predictParams <- PredictParams(NULL, weighted = "unweighted", weight = "height difference",
                               getClasses = function(result) result)
```

## DD Cross-validated Classification

As was done for DM classification, 20 permutations and 5 fold cross-validation is done. It takes substantially longer to complete than DM classification, because thousands of kernel densities are being esimated for each iteration.

```{r}
classifiedDD <- runTests(measurementsVS, classes, "AML", "Changes in Distributions",
                         params = list(selectParams, trainParams, predictParams),
                         permutations = 20, seed = 2018)
classifiedDD
```

Evaluation of these three classifiers will be made in the subsequent tutorial.