---
title: "Selecting Biomarkers and Making Predictions"
author: "Dr Ellis Patrick, Dr Dario Strbenac, Dr Shila Ghazanfar, Prof Jean Yang"
date: "29 June 2018"
output:
  html_document:
    code_folding: show
    number_sections: yes
    self_contained: yes
    toc: true
    toc_float: true
    toc_depth: 1
    theme: yeti
editor_options: 
  chunk_output_type: console
---

```{r, echo = FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
knitr::opts_chunk$set(results = "hide", fig.show = "hide")
options(width = 91)
```

# Activity Overview

- Loading RNA-seq data set: Acute Myeloid Leukaemia treatment resistance

- Cleaning and transformation

- Fitting widely used classifiers to a simple partition of the data set

# Preparation

To complete today's workshops, you will need to have R and Rstudio installed on your computer. Before attending the workshop, ensure R is at least version 3.5.0. Please see README file for more information. 

To install Bioconductor software, BiocManager must firstly be obtained from CRAN.

```
install.packages("BiocManager")
library(BiocManager)
```

Install ClassifyR using

```
install("ClassifyR", dependencies = TRUE)
```

Additionally, DESeq2, EDASeq and genefilter are used for some exploratory visualisations and analysis. They can be installed by running the command

```
install(c("DESeq2", "EDASeq", "genefilter"))
```

# RNA-seq Data Set: Acute Myeloid Leukaemia (AML) Treatment Resistance

- Primary therapy resistance is a major problem in acute myeloid leukemia treatment. Approximately 20-30% of younger adult patients with AML and as many as 50% of older adults are refractory to induction treatment.

- Research findings are <a href="http://www.haematologica.org/content/103/3/456" target="_blank">published</a> in *Haematologica* in 2018.

- The data is available from <a href="https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE106291" target="_blank">GEO Browser</a> as 250 `txt.gz` files of gene-level read counts or a Microsoft Excel file where the gene expression values were standardised to have a mean of 0 and variance of 1.

### Import Prepared Files From GitHub 

Importing RNA-seq data from GEO Browser into R is a difficult process. Import the prepared tab-separated text files of RNA-seq read counts and clinical data from GitHub.

```{r}
readCounts <- read.delim(url("https://raw.githubusercontent.com/SydneyBioX/localWorkshop/master/data/counts.txt"), check.names = FALSE)
readCounts <- as.matrix(readCounts)
sampleInfo <- read.delim(url("https://raw.githubusercontent.com/SydneyBioX/localWorkshop/master/data/samples.txt"), check.names = FALSE)
```

`check.names = FALSE` prevents R unnecessarily changing hyphens and spaces in column names to periods.

## Reflection: Download and Format Tables From GEO

This exercise is observational; **you don't need to run the code or understand it**.

Unfortunately, standards and protocols for uploading gene expression data to repositories such as GEO have become very lax in recent years. GEO is well-standardised for microarray datasets but not so for RNA-Seq (due to multiple ways to dealing with the sequenced reads). As a result, there are very clean and standardised ways to load data from GEO into R for microarray data, however this is now not the case for RNA-Seq data. For completeness, below is the code that we used to download and load the AML data into R. Observe that the process is not streamlined, but do not run the code.

```{r, eval = FALSE}
library(GEOquery)
library(tools)

clinical <- pData(getGEO("GSE106291")[[1]])
keepColumns <- c("title", "characteristics_ch1.2", "characteristics_ch1.3",
                 "characteristics_ch1.4", "characteristics_ch1.5",
                 "characteristics_ch1.6", "characteristics_ch1.8",
                 "characteristics_ch1.9")
clinical <- clinical[, keepColumns]
colnames(clinical) <- c("ID", "Gender", "Age", "Response", "Survival Time", "Status",
                        "RUNX1-RUNX1T1 Fusion", "RUNX1 Mutation")
clinical <- data.frame(lapply(clinical, as.character),
                       check.names = FALSE, stringsAsFactors = FALSE)
removedColumnNames <- lapply(clinical, function(dataColumn)
                             toTitleCase(gsub(".*: ", '', dataColumn)))
clinical <- data.frame(removedColumnNames, check.names = FALSE)

library(readr)
tempFile <- file.path(tempdir(), "countsPack.tar")
download.file("https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE106291&format=file",
              destfile = tempFile)
untar(tempFile, exdir = dirname(tempFile))
countsFiles <- list.files(dirname(tempFile), "^GSM", full.names = TRUE)
sampleCounts <- lapply(countsFiles, function(file)
                       read_delim(file, '\t', col_names = FALSE))
countsMatrix <- do.call(cbind, lapply(sampleCounts, "[[", 2))
rownames(countsMatrix) <- sampleCounts[[1]][[1]]
colnames(countsMatrix) <- sapply(strsplit(basename(countsFiles), '_'), '[', 2)
```

## Explore the Clinical Data

The clinical data provides information about several different characteristics of the patients. Verify that there is data for 250 patients.<br>
**Hint**: `sampleInfo` is a `data.frame`. Each row stores data for one patient.

```{r}
head(sampleInfo)
nrow(sampleInfo)
```

Observe the number of samples which are resistant to treatment and which are not.

```{r}
table(sampleInfo[, "Response"], useNA = "always")
```

There are 15 patients with missing data regarding their resistance. Identify which rows of the clinical data they are in and remove the samples.

```{r}
removeClinical <- which(is.na(sampleInfo[, "Response"]))
readCounts <- readCounts[, -removeClinical]
sampleInfo <- sampleInfo[-removeClinical, ]
```

Remove outcome variables other than Response from the clinical table.

```{r}
ignoreClinical <- match(c("Status", "Survival Time"), colnames(sampleInfo))
sampleInfo <-sampleInfo[, -ignoreClinical]
```

# Processing RNA-Seq data 

## Properties of RNA-seq Measurements 

RNA-seq count tables have a couple of properties which need to be accounted for.

1. Different samples may have a different total number of reads. A particular sample with 10 million reads will have 0 reads counted for genes that will have non-zero counts if the same sample had 100 million reads.

2. The variance of counts increases as the mean count increases when considering the trend based on all of the genes. Most classifiers require that the input data set have a constant variance across the range of means.

We will use the R package DESeq2 to transform our data to account for these to issues. This will follow many of the steps in the DESeq2 vignette https://bioconductor.org/packages/release/bioc/vignettes/DESeq2/inst/doc/DESeq2.html .

## Load counts into DESeq2 format

To use DESeq2 to transform our data, we will need to load it into a DESeq2 object.
```{r message=FALSE}
library(DESeq2)

# Convert our counts into a DESeqDataSet
DS2set <- DESeqDataSetFromMatrix(countData = readCounts,
                              colData = data.frame(colNames = colnames(readCounts)),
                              design = ~ 1)
```

We will remove all genes with zero counts in 200 or more samples to remove genes with no predictive power from taking up computing time.<br>
We will use `==` to test for zeros.

```{r}
keep <- rowSums(counts(DS2set) == 0) < 200
DS2set <- DS2set[keep,]
```

## Read Total / Library Size Differences

As typical for omics data and in contrast to clinical data, the genes are stored in rows and the samples in columns. Identify the number of genes and samples.<br>
**Hint**: Use either `dim` or `nrow` and `ncol` functions.

```{r}
readCounts[1:5, 1:5]
dim(readCounts)
```

The number of reads per sample varies widely betwen patients by as much as 10-fold.

```{r}
samplesCounts <- colSums(counts(DS2set))
countsSummary <- summary(samplesCounts)
countsSummary
```

The limit of detection would be quite different between samples. We can also visualise this with a boxplot where we see that the distribution of gene expression values of each sample look quite different.

```{r, fig.height = 6, fig.width = 12}
boxplot(counts(DS2set)[, 1:50], ylim = c(0, 1500),
        main = "Gene Counts", ylab = "Counts", cex = 0.25, xaxt = 'n')
```

We can alleviate this issue by scaling each column to have a similar number of counts. We will do this using the normalization procedure in DESeq2 `estimateSizeFactors`.

```{r}
DS2set <- estimateSizeFactors(DS2set)
```

Note how the disributions of counts per patient are now much more similar.

```{r, fig.height = 6, fig.width = 12}
boxplot(counts(DS2set, normalize=TRUE)[, 1:50], ylim = c(0, 1500),
        main = "Gene Counts", ylab = "Scaled Counts", cex = 0.25, xaxt = 'n')
```

## Mean-variance relationship

The variance of counts increases as the mean count increases when considering the trend based on all of the genes.

The Bioconductor package [EDASeq](https://bioconductor.org/packages/release/bioc/html/EDASeq.html) contains function for **e**xploratory **d**ata **a**nalysis of RNA-**seq**. Observe the mean-variance relationship of the scaled counts.<br>
**Hint**: EDASeq doesn't work with a matrix, but a `SeqExpressionSet` object. Read the documentation for how to create one by using the R command `?SeqExpressionSet`. A mean-variance plot can be drawn by `meanVarPlot`.

```{r, message = FALSE, warning = FALSE, fig.align = "center", fig.height = 5, fig.width = 5}
library(EDASeq)
AMLExpressionSet <- newSeqExpressionSet(counts(DS2set,normalize = TRUE))
meanVarPlot(AMLExpressionSet, log = TRUE, main = "Mean-Variance Plot")
```

The red line is calculated from the data whereas the black line shows the mean and variance being the same value. Notice how the experimental variance increases at a faster rate than the mean $\equiv$ variance line, a trend commonly termed _overdispersion_.

Most classifiers require that the input data set have a constant variance across the range of means. Using DESeq2's `vst` function, remove the relationship of variance to mean. Add the normalised values into the `AMLExpressionSet` object.<br>
**Hint**: Check the documentation of `normCounts` for how to add normalised values to a `SeqExpressionSet` object.

```{r, warning = FALSE}
measurementsVS <- assay(vst(DS2set))
```

Visualise again the relationship between mean and variance.

```{r, fig.align = "center", fig.height = 5, fig.width = 5}
normCounts(AMLExpressionSet) <- measurementsVS
meanVarPlot(AMLExpressionSet, xlim = c(3, 9), ylim = c(0, 9), main = "Mean-Variance Plot")
```

Notice that the variance is now fairly constant across the range of means.

Before doing any classification, the number of genes will be reduced to make feature selection faster. Keep the top 2000 most variable genes.<br>
**Hint**: Use `var` in conjunction with `apply` to calculate the variance of each row of the stabilised values. Use `?order` to check how to make the `order` function sort values in descending order.

```{r}
geneVariances <- apply(measurementsVS, 1, var)
mostVariable <- order(geneVariances, decreasing = TRUE)[1:2000]
measurementsVS <- measurementsVS[mostVariable, ]
measurementsVS[1:6, 1:6]
```

Class information is not used, so the filtering is fair. The most variable gene is XIST, a gene involved with X chromosome inactivation, a process by which one of the two copies of the X chromosome present in female mammals is inactivated.

# Simple Classification

Before the ClassifyR framework is used, simple illustrative classifications using three classifiers are done.

Calculate the number of samples belonging to each class.

```{r}
classes <- sampleInfo[, "Response"]
table(classes)
```

## Training and Test Sets

Split the samples into a training set and a test set.

```{r}
testIndex = 150:235
geneTrain <- measurementsVS[, -testIndex]
geneTest <- measurementsVS[, testIndex]
clinicalTrain <- sampleInfo[-testIndex, ]
clinicalTest <- sampleInfo[testIndex, ]
classesTrain <- classes[-testIndex]
classesTest <- classes[testIndex]
```

## Feature Selection

For many classification methods, it helps to input only genes which you feel will be useful for the prediction; including non-informative genes could introduce noise or facilitate over-fitting. For many of the following methods, we will use the 10 largest absolute t-statistics. The `rowttests` function enables thousands of t-tests to be calculated quickly. The 10 best features are chosen for illustration; this number should more generally be determined in a thoughtful way.

```{r, message = FALSE}
library(genefilter)
tStatistic <- rowttests(geneTrain, classesTrain)[["statistic"]]
best10T <- order(abs(tStatistic), decreasing = TRUE)[1:10]
```

## Diagonal Linear Discriminant Analysis (DLDA)

An implementation of DLDA is provided by the R package sparsediscrim. The `dlda` function trains the classifier and the `predict` function is used to make predictions on test data. It requires that the features be the columns of the table. We will use the top 10 most differentially expressed genes in the model.

```{r}
library(sparsediscrim)

# Build DLDA classifier
DLDAclassifier <- dlda(t(geneTrain[best10T, ]), classesTrain)

# Use the classifier to predict classes of some new samples
testResult <- predict(DLDAclassifier, t(geneTest))
DLDAclasses <- testResult[["class"]]

# Calculate confusion matrix
DLDAconfusion <- table(actual = classesTest, predicted = DLDAclasses)
DLDAconfusion

# Calculate accuracy as the number of predictions the model got correct
sum(diag(DLDAconfusion))/sum(DLDAconfusion)
```

There are `r sum(diag(DLDAconfusion))` samples correctly predicted and `r sum(DLDAconfusion) - sum(diag(DLDAconfusion))` samples incorrectly predicted.

## Logistic Regression 

### Logistic Regression on clinical data

Logistic regression is a well established statistical method for performing classification. This technique is useful for classifying the clinical data as it works seamlessly with numeric and categorical data. R's `glm` function can build such a classifier if there are exactly 2 classes of samples. The `predict` function is used to make predictions for the test set samples. The option `type = "response"` specifies that probabilities should be calculated. There's no option to output class labels directly.

RUNX1-RUNX1T1 Fusion is rare and removed from the analysis because it only happens for 3 people. Every factor variable in the input table for logistic regression must have at least one observation in each class.

```{r}
fusionColumn <- match("RUNX1-RUNX1T1 Fusion", colnames(clinicalTrain))

# Perform logistic regression 
LRclassifier <- glm(Response ~ ., "binomial", clinicalTrain[, -fusionColumn])

# Predict classes by probability > 0.5
LRprobabilities <- predict(LRclassifier, clinicalTest[, -fusionColumn], type = "response")
LRclasses <- ifelse(LRprobabilities > 0.5, levels(classes)[2], levels(classes)[1])

# Calculate confusion matrix. 
LRconfusion <- table(actual = classesTest, predicted = LRclasses)
LRconfusion

# Calculate accuracy as the number of predictions the model got correct
sum(diag(LRconfusion))/sum(LRconfusion)
```

There are `r sum(diag(LRconfusion))` samples correctly predicted and `r sum(LRconfusion) - sum(diag(LRconfusion))` samples incorrectly predicted.

<br>

By looking at which variables were significant in the model, we may get an intuition for which variables are important. Here we see age as important.


```{r}
summary(LRclassifier)
```

## Support Vector Machine: A Non-Linear Boundary Classifier

An SVM classifier may either use a linear or non-linear boundary, depending on the user's choice of *kernel*. Understanding how it works requires an undersanding of convex optimisation, so that is not covered in this course.

The svm function in R is provided by a third programmer who developed a package named e1071. The default kernel used is the radial basis function kernel which calculates a non-linear boundary. Like many classical statistical classifiers, it requires the **genes** to be the **columns** of the matrix and the **samples** to be the **rows** of the matrix. The prediction function returns a factor of the predicted classes, unlike the other two algorithms which returned more infomation in a list.

```{r}
library(e1071)

X = as.data.frame(t(geneTrain[best10T,]))
y = clinicalTrain$Response
newX = as.data.frame(t(geneTest[best10T,]))

SVMclassifierGene <- svm(X,y)
SVMclassesGene <- predict(SVMclassifierGene, newX)


# Calculate confusion matrix. 
SVMconfusionGene <- table(actual = classesTest, predicted = SVMclassesGene)
SVMconfusionGene

# Calculate accuracy as the number of predictions the model got correct

sum(diag(SVMconfusionGene))/sum(SVMconfusionGene)
```

## Random Forest: A Non-Linear Boundary Classifier

A random forest is a set of decision trees which each guess the class of each sample. The class which has the most common guesses for a particular sample is predicted as that sample's class. The decision boundary is often non-linear. For example, IF value < 5 AND IF value > 11 THEN Poor.

Random forests in R are provided by the package *randomForest*. Random forests have a large number of options. Here, the default values are used. It requires the **genes** to be the **columns** of the matrix and the **samples** to be the **rows** of the matrix.

Unlike dlda, randomForest takes the training data and test data all as inputs to one function. Also, the predicted classes are stored in the list element named "predicted". Each programmer has his/her own convention and classification code written for one classifer won't work for another.

```{r}
library(randomForest)
X = as.data.frame(t(geneTrain[best10T,]))
y = clinicalTrain$Response
newX = as.data.frame(t(geneTest[best10T,]))

# Build a modekl and predict.
RFclassifierGene <- randomForest(X,y)
RFclassesGene <- predict(RFclassifierGene, newX)

# Calculate confusion matrix. 
RFconfusionGene <- table(actual = classesTest, predicted = RFclassesGene)
RFconfusionGene

# Calculate accuracy as the number of predictions the model got correct

sum(diag(RFconfusionGene))/sum(RFconfusionGene)
```

## naive Bayes classifier

Again, feature selection is necessary. The 10 largest Kolmogorov-Smirnov test statistics will be used.

```{r, warning = FALSE}
trainSensitive <- geneTrain[, classesTrain == "Sensitive"]
trainResistant <- geneTrain[, classesTrain == "Resistant"]
trainSensitive <- as.list(as.data.frame(t(trainSensitive)))
trainResistant <- as.list(as.data.frame(t(trainResistant)))

KS <- mapply(function(sensValues, resValues)
                      ks.test(sensValues, resValues)[["statistic"]],
             trainSensitive, trainResistant)
best10KS <- order(abs(KS), decreasing = TRUE)[1:10]
```

An implementation of naive Bayes is provided by the R package e1071. The `naiveBayes` function trains the classifier and the `predict` function is used to make predictions on test data. It requires that the features be the columns of the table.

```{r}
library(e1071)
NBclassifier <- naiveBayes(t(geneTrain[best10KS, ]), classesTrain)
NBclasses <- predict(NBclassifier, t(geneTest))
NBconfusion <- table(actual = classesTest, predicted = NBclasses)
NBconfusion
```

There are `r sum(diag(NBconfusion))` samples correctly predicted and `r sum(NBconfusion) - sum(diag(NBconfusion))` samples incorrectly predicted.

<span style = "font-size:34px;font-weight:300"> After the Break </span>

- Basic cross-validation

- Introduction to ClassifyR
